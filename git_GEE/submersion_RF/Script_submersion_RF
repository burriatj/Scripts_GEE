/**** Start of imports. If edited, may not auto-convert in the playground. ****/
var Train_dataset = ee.FeatureCollection("projects/bjuser123/assets/Train_dataset"),
    Train_boundaries = ee.FeatureCollection("projects/bjuser123/assets/Train_boundaries"),
    ROI = 
    /* color: #0000ff */
    /* shown: false */
    /* displayProperties: [
      {
        "type": "rectangle"
      }
    ] */
    ee.Geometry.Polygon(
        [[[-2.5271507074253474, 47.31441654957819],
          [-2.5271507074253474, 47.282460012726254],
          [-2.4667259027378474, 47.282460012726254],
          [-2.4667259027378474, 47.31441654957819]]], null, false);
/***** End of imports. If edited, may not auto-convert in the playground. *****/
//////////////////// CLASSIFICATION DU NIVEAU D'HUMIDITE DU SOL//////////////////////////

// Pour changer la zone à classifier remplacer ROI dans la ligne ci-dessous par le nom de la zone (en violet)
var AOI = ROI;

// Indiquer le SCR de la zone à classifier (en rouge)
var CRSclass = 'EPSG: 2154';


// Nommer le dossier dans lequel enregistrer le mnt (en rouge)
var dossier = 'data_ROI';

// Si vous disposez de votre propre jeu d'entrainement :
// Modifier l'emprise sur lequel le jeux de données est situé (en violet)
var Emprise_train = Train_boundaries;

// Modifier le jeu de données et indiquer son SCR (en rouge)
var JDD_train = Train_dataset;

var CRStrain = 'EPSG: 2154';

var labelclasse = 'code';

                                                            Map.centerObject(AOI,13);

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////// ETAPE 1 : MODELISATION    //////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////////////////////////


////////////////////// CREATION VARIABLES POUR L'ENTRAINEMENT //////////////////////////

/////// SENTINEL-1 Bande VV

var s1 = ee.ImageCollection('COPERNICUS/S1_GRD')
        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))
        .filter(ee.Filter.or(ee.Filter.eq('orbitProperties_pass', 'DESCENDING'), ee.Filter.eq('orbitProperties_pass','ASCENDING')));

var filtered1 = s1
  .filter(ee.Filter.date('2022-01-01','2022-12-31'))
  .filter(ee.Filter.bounds(Emprise_train));
  
var filtered2 = s1
  .filter(ee.Filter.date('2021-01-01','2021-12-31'))
  .filter(ee.Filter.bounds(Emprise_train));
  
var filtered3 = s1
  .filter(ee.Filter.date('2020-01-01','2020-12-31'))
  .filter(ee.Filter.bounds(Emprise_train));
  
var dataset = filtered1.merge(filtered2).merge(filtered3);

print('S1 - Collection P1 train',dataset.size());

//reduction _std
var im_std = dataset.reduce({
reducer: ee.Reducer.stdDev()});
var reprojected = im_std.reproject(CRStrain, null, 10);
var clipped_image = reprojected.clip(Emprise_train);
var vvstd = clipped_image.select('VV_stdDev');
//Map.addLayer(vvstd,{min:-5,max:5},'vvstd');


//reduction _min
var im_min = dataset.min();
var reprojected = im_min.reproject(CRStrain, null, 10);
var clipped_image = reprojected.clip(Emprise_train);
var vvmin = clipped_image.select('VV');
//Map.addLayer(vvmin,{min:-25,max:5},'vvmin');

//reduction _q1
var im_meanb = dataset.reduce({
reducer: ee.Reducer.percentile([1])});
var reprojected = im_meanb.reproject(CRStrain, null, 10);
var clipped_image = reprojected.clip(Emprise_train);
var vvmean_q1 = clipped_image.select('VV_p1');
//Map.addLayer(vvmean_q1,{min:-25,max:5},'vvmean_q1');


//reduction _q8
var im_meanb = dataset.reduce({
reducer: ee.Reducer.percentile([8])});
var reprojected = im_meanb.reproject(CRStrain, null, 10);
var clipped_image = reprojected.clip(Emprise_train);
var vvmean_q8 = clipped_image.select('VV_p8');
//Map.addLayer(vvmean_q8,{min:-25,max:5},'vvmean_q8');

//reduction _q25
var im_meanb = dataset.reduce({
reducer: ee.Reducer.percentile([25])});
var reprojected = im_meanb.reproject(CRStrain, null, 10);
var clipped_image = reprojected.clip(Emprise_train);
var vvmean_q25 = clipped_image.select('VV_p25');
//Map.addLayer(vvmean_q25,{min:-25,max:5},'vvmean_q25');

//reduction _q50
var im_meanb = dataset.reduce({
reducer: ee.Reducer.percentile([50])});
var reprojected = im_meanb.reproject(CRStrain, null, 10);
var clipped_image = reprojected.clip(Emprise_train);
var vvmean_q50 = clipped_image.select('VV_p50');
//Map.addLayer(vvmean_q50,{min:-13,max:-8},'vvmean_q50');


/////// SENTINEL-2 EVI periode 3


var s2 = ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED");

var filtered1 = s2
  .filter(ee.Filter.date('2022-07-01','2022-09-30'))
  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 50))
  .filter(ee.Filter.bounds(Emprise_train));
  
var filtered2 = s2
  .filter(ee.Filter.date('2021-07-01','2021-09-30'))
  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 50))
  .filter(ee.Filter.bounds(Emprise_train));
  
var filtered3 = s2
  .filter(ee.Filter.date('2020-07-01','2020-09-30'))
  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 50))
  .filter(ee.Filter.bounds(Emprise_train));
  
var filtered = filtered1.merge(filtered2).merge(filtered3);

print('S2 - Collection P3 train',filtered.size());

// Write a function for Cloud masking
function maskCloudAndShadowsSR(image) {
  var cloudProb = image.select('MSK_CLDPRB');
  var snowProb = image.select('MSK_SNWPRB');
  var cloud = cloudProb.lt(5);
  var snow = snowProb.lt(5);
  var scl = image.select('SCL'); 
  var shadow = scl.eq(3); // 3 = cloud shadow
  var cirrus = scl.eq(10); // 10 = cirrus
  // Cloud probability less than 5% or cloud shadow classification
  var mask = (cloud.and(snow)).and(cirrus.neq(1)).and(shadow.neq(1));
  return image.updateMask(mask).divide(10000)
      .select("B.*")
      .copyProperties(image, ["system:time_start"]);
}

var filtered = filtered.map(maskCloudAndShadowsSR)

// Add a band containing timestamp to each image
// This will be used to do pixel-wise interpolation later
var filtered = filtered.map(function(image) {
  var timeImage = image.metadata('system:time_start').rename('timestamp')
  // The time image doesn't have a mask. 
  // We set the mask of the time band to be the same as the first band of the image
  var timeImageMasked = timeImage.updateMask(image.mask().select(0))
  return image.addBands(timeImageMasked)
})

// Specify the time-window
// This will determine how much backward and forward are we willing to
// look for an unmasked pixel in the time-series
var days = 30

// For each image in the collection, we need to find all images
// before and after the specified time-window

// This is accomplished using Joins
// We need to do 2 joins
// Join 1: Join the collection with itself to find all images before each image
// Join 2: Join the collection with itself to find all images after each image

// We first define the filters needed for the join

// Define a maxDifference filter to find all images within the specified days
// The filter needs the time difference in milliseconds
// Convert days to milliseconds
var millis = ee.Number(days).multiply(1000*60*60*24)
var maxDiffFilter = ee.Filter.maxDifference({
  difference: millis,
  leftField: 'system:time_start',
  rightField: 'system:time_start'
})

// We need a lessThanOrEquals filter to find all images after a given image
// This will compare the given image's timestamp against other images' timestamps
var lessEqFilter = ee.Filter.lessThanOrEquals({
  leftField: 'system:time_start',
  rightField: 'system:time_start'
})

// We need a greaterThanOrEquals filter to find all images before a given image
// This will compare the given image's timestamp against other images' timestamps
var greaterEqFilter = ee.Filter.greaterThanOrEquals({
  leftField: 'system:time_start',
  rightField: 'system:time_start'
})

// Apply the joins

// For the first join, we need to match all images that are after the given image.
// To do this we need to match 2 conditions
// 1. The resulting images must be within the specified time-window of target image
// 2. The target image's timestamp must be lesser than the timestamp of resulting images
// Combine two filters to match both these conditions
var filter1 = ee.Filter.and(maxDiffFilter, lessEqFilter)
// This join will find all images after, sorted in descending order
// This will gives us images so that closest is last
var join1 = ee.Join.saveAll({
  matchesKey: 'after',
  ordering: 'system:time_start',
  ascending: false})
  
var join1Result = join1.apply({
  primary: filtered,
  secondary: filtered,
  condition: filter1
})
// Each image now as a property called 'after' containing
// all images that come after it within the time-window
print(join1Result.first())

// Do the second join now to match all images within the time-window
// that come before each image
var filter2 = ee.Filter.and(maxDiffFilter, greaterEqFilter)
// This join will find all images before, sorted in ascending order
// This will gives us images so that closest is last
var join2 = ee.Join.saveAll({
  matchesKey: 'before',
  ordering: 'system:time_start',
  ascending: true})
  
var join2Result = join2.apply({
  primary: join1Result,
  secondary: join1Result,
  condition: filter2
})

// Each image now as a property called 'before' containing
// all images that come after it within the time-window
print(join2Result.first())


// Do the interpolation

// We now write a function that will be used to interpolate all images
// This function takes an image and replaces the masked pixels
// with the interpolated value from before and after images.

var interpolateImages = function(image) {
  var image = ee.Image(image)
  // We get the list of before and after images from the image property
  // Mosaic the images so we a before and after image with the closest unmasked pixel
  var beforeImages = ee.List(image.get('before'))
  var beforeMosaic = ee.ImageCollection.fromImages(beforeImages).mosaic()
  var afterImages = ee.List(image.get('after'))
  var afterMosaic = ee.ImageCollection.fromImages(afterImages).mosaic()

  // Interpolation formula
  // y = y1 + (y2-y1)*((t – t1) / (t2 – t1))
  // y = interpolated image
  // y1 = before image
  // y2 = after image
  // t = interpolation timestamp
  // t1 = before image timestamp
  // t2 = after image timestamp
  
  // We first compute the ratio (t – t1) / (t2 – t1)

  // Get image with before and after times
  var t1 = beforeMosaic.select('timestamp').rename('t1')
  var t2 = afterMosaic.select('timestamp').rename('t2')

  var t = image.metadata('system:time_start').rename('t')

  var timeImage = ee.Image.cat([t1, t2, t])

  var timeRatio = timeImage.expression('(t - t1) / (t2 - t1)', {
    't': timeImage.select('t'),
    't1': timeImage.select('t1'),
    't2': timeImage.select('t2'),
  })
  // You can replace timeRatio with a constant value 0.5
  // if you wanted a simple average
  
  // Compute an image with the interpolated image y
  var interpolated = beforeMosaic
    .add((afterMosaic.subtract(beforeMosaic).multiply(timeRatio)))
  // Replace the masked pixels in the current image with the average value
  var result = image.unmask(interpolated)
  return result.copyProperties(image, ['system:time_start'])
}

// map() the function to interpolate all images in the collection
var dataset = ee.ImageCollection(join2Result.map(interpolateImages))

//reduction _mean
var im_mean = dataset.reduce({
reducer: ee.Reducer.intervalMean(10, 90)});

//reduction _meanb
var im_meanb = dataset.reduce({
reducer: ee.Reducer.intervalMean(5, 20)});

//reduction _meanh
var im_meanh = dataset.reduce({
reducer: ee.Reducer.intervalMean(80, 95)});

var image = im_mean.addBands(im_meanb).addBands(im_meanh);

var reprojected = image
        .reproject(CRStrain, null, 10);

var final_image = reprojected.clip(Emprise_train);


var evi3h = final_image.expression ('(2.5*nir-red*(nir+6*red-7.5*bleue)+1)', {
      'nir': final_image.select('B8_mean_2'),
      'red': final_image.select('B4_mean'),
      'bleue': final_image.select('B2_mean'),
}).rename('evi3h');
//Map.addLayer(evi3h,{min:1,max:2},'evi3h_07_09');


////// OVERLAY

/////////// Creation de la stack de variables train

//Image Stack
var newBands = ee.Image([vvmean_q1, vvmean_q8, vvmean_q25, vvmean_q50, evi3h
  ]);

var stack = vvmin.addBands(newBands);
////Map.addLayer(stack,{},'stack');

var bands = [
'vvmin','vvmean_q1','vvmean_q8','vvmean_q25','vvmean_q50', 'evi3h'
  ];

////////// Overlay

//Choix des variables et du label de classif
var training = JDD_train;
var label = labelclasse;

// Overlay the points on the imagery to get training.
var training = stack.select(bands).sampleRegions({
  collection: JDD_train,
  properties: [label],
  scale: 10
});

// Filter out the null property values and try again.
var trainingSample = training.filter(
  ee.Filter.notNull(training.first().propertyNames())
);



////////////////////////////////////// Random Forest ////////////////////////////////////////////////


// Add a random value field to the sample and use it to approximately split 80%
// of the features into a training set and 20% into a validation set.
var sample = JDD_train.randomColumn();
var trainingSample = sample.filter('random <= 0.8');
var validationSample = sample.filter('random > 0.8');

//training
var training = stack.sampleRegions({
    collection: trainingSample,
    properties: [labelclasse],
    scale: 10
});

var validation = stack.sampleRegions({
    collection: validationSample,
    properties: [labelclasse],
    scale: 10
});

//RF Classifier Model Building
//ee.Classifier.smileRandomForest(numberOfTrees, 
//variablesPerSplit, minLeafPopulation, bagFraction, maxNodes, seed)
var RFclassifier = ee.Classifier.smileRandomForest(500,6,1,0.5,20).train(training, labelclasse);

//////////////////////////////////////////////////////////////////////////////////////////////
///////////////////////////ETAPE 2 : CLASSIFICATION //////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////

////////////////////// CREATION VARIABLES POUR LA CLASSIFIACTION //////////////////////////

/////// SENTINEL-1 Bande VV

var s1 = ee.ImageCollection('COPERNICUS/S1_GRD')
        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))
        .filter(ee.Filter.or(ee.Filter.eq('orbitProperties_pass', 'DESCENDING'), ee.Filter.eq('orbitProperties_pass','ASCENDING')));

var filtered1 = s1
  .filter(ee.Filter.date('2022-01-01','2022-12-31'))
  .filter(ee.Filter.bounds(AOI));
  
var filtered2 = s1
  .filter(ee.Filter.date('2021-01-01','2021-12-31'))
  .filter(ee.Filter.bounds(AOI));
  
var filtered3 = s1
  .filter(ee.Filter.date('2020-01-01','2020-12-31'))
  .filter(ee.Filter.bounds(AOI));
  
var dataset = filtered1.merge(filtered2).merge(filtered3);

print('S1 - Collection P1 classif',dataset.size());

//reduction _std
var im_std = dataset.reduce({
reducer: ee.Reducer.stdDev()});
var reprojected = im_std.reproject(CRSclass, null, 10);
var clipped_image = reprojected.clip(AOI);
var vvstd = clipped_image.select('VV_stdDev');
//Map.addLayer(vvstd,{min:-5,max:5},'vvstd');


//reduction _min
var im_min = dataset.min();
var reprojected = im_min.reproject(CRSclass, null, 10);
var clipped_image = reprojected.clip(AOI);
var vvmin = clipped_image.select('VV');
//Map.addLayer(vvmin,{min:-25,max:5},'vvmin');

//reduction _q1
var im_meanb = dataset.reduce({
reducer: ee.Reducer.percentile([1])});
var reprojected = im_meanb.reproject(CRSclass, null, 10);
var clipped_image = reprojected.clip(AOI);
var vvmean_q1 = clipped_image.select('VV_p1');
//Map.addLayer(vvmean_q1,{min:-25,max:5},'vvmean_q1');


//reduction _q8
var im_meanb = dataset.reduce({
reducer: ee.Reducer.percentile([8])});
var reprojected = im_meanb.reproject(CRSclass, null, 10);
var clipped_image = reprojected.clip(AOI);
var vvmean_q8 = clipped_image.select('VV_p8');
//Map.addLayer(vvmean_q8,{min:-25,max:5},'vvmean_q8');

//reduction _q25
var im_meanb = dataset.reduce({
reducer: ee.Reducer.percentile([25])});
var reprojected = im_meanb.reproject(CRSclass, null, 10);
var clipped_image = reprojected.clip(AOI);
var vvmean_q25 = clipped_image.select('VV_p25');
//Map.addLayer(vvmean_q25,{min:-25,max:5},'vvmean_q25');

//reduction _q50
var im_meanb = dataset.reduce({
reducer: ee.Reducer.percentile([50])});
var reprojected = im_meanb.reproject(CRSclass, null, 10);
var clipped_image = reprojected.clip(AOI);
var vvmean_q50 = clipped_image.select('VV_p50');
//Map.addLayer(vvmean_q50,{min:-15,max:-8},'vvmean_q50');

//reduction _q75
var im_meanb = dataset.reduce({
reducer: ee.Reducer.percentile([75])});
var reprojected = im_meanb.reproject(CRSclass, null, 10);
var clipped_image = reprojected.clip(AOI);
var vvmean_q75 = clipped_image.select('VV_p75');
//Map.addLayer(vvmean_q75,{min:-15,max:-8},'vvmean_q75');

//reduction _q90
var im_meanb = dataset.reduce({
reducer: ee.Reducer.percentile([90])});
var reprojected = im_meanb.reproject(CRSclass, null, 10);
var clipped_image = reprojected.clip(AOI);
var vvmean_q90 = clipped_image.select('VV_p90');
//Map.addLayer(vvmean_q90,{min:-15,max:-8},'vvmean_q90');


/////// SENTINEL-2 EVI periode 3

var s2 = ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED");

var filtered1 = s2
  .filter(ee.Filter.date('2022-07-01','2022-09-30'))
  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 50))
  .filter(ee.Filter.bounds(AOI));
  
var filtered2 = s2
  .filter(ee.Filter.date('2021-07-01','2021-09-30'))
  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 50))
  .filter(ee.Filter.bounds(AOI));
  
var filtered3 = s2
  .filter(ee.Filter.date('2020-07-01','2020-09-30'))
  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 50))
  .filter(ee.Filter.bounds(AOI));
  
var filtered = filtered1.merge(filtered2).merge(filtered3);

print('S2 - Collection P3 classif',filtered.size());

// Write a function for Cloud masking
function maskCloudAndShadowsSR(image) {
  var cloudProb = image.select('MSK_CLDPRB');
  var snowProb = image.select('MSK_SNWPRB');
  var cloud = cloudProb.lt(5);
  var snow = snowProb.lt(5);
  var scl = image.select('SCL'); 
  var shadow = scl.eq(3); // 3 = cloud shadow
  var cirrus = scl.eq(10); // 10 = cirrus
  // Cloud probability less than 5% or cloud shadow classification
  var mask = (cloud.and(snow)).and(cirrus.neq(1)).and(shadow.neq(1));
  return image.updateMask(mask).divide(10000)
      .select("B.*")
      .copyProperties(image, ["system:time_start"]);
}

var filtered = filtered.map(maskCloudAndShadowsSR)

// Add a band containing timestamp to each image
// This will be used to do pixel-wise interpolation later
var filtered = filtered.map(function(image) {
  var timeImage = image.metadata('system:time_start').rename('timestamp')
  // The time image doesn't have a mask. 
  // We set the mask of the time band to be the same as the first band of the image
  var timeImageMasked = timeImage.updateMask(image.mask().select(0))
  return image.addBands(timeImageMasked)
})

// Specify the time-window
// This will determine how much backward and forward are we willing to
// look for an unmasked pixel in the time-series
var days = 30

// For each image in the collection, we need to find all images
// before and after the specified time-window

// This is accomplished using Joins
// We need to do 2 joins
// Join 1: Join the collection with itself to find all images before each image
// Join 2: Join the collection with itself to find all images after each image

// We first define the filters needed for the join

// Define a maxDifference filter to find all images within the specified days
// The filter needs the time difference in milliseconds
// Convert days to milliseconds
var millis = ee.Number(days).multiply(1000*60*60*24)
var maxDiffFilter = ee.Filter.maxDifference({
  difference: millis,
  leftField: 'system:time_start',
  rightField: 'system:time_start'
})

// We need a lessThanOrEquals filter to find all images after a given image
// This will compare the given image's timestamp against other images' timestamps
var lessEqFilter = ee.Filter.lessThanOrEquals({
  leftField: 'system:time_start',
  rightField: 'system:time_start'
})

// We need a greaterThanOrEquals filter to find all images before a given image
// This will compare the given image's timestamp against other images' timestamps
var greaterEqFilter = ee.Filter.greaterThanOrEquals({
  leftField: 'system:time_start',
  rightField: 'system:time_start'
})

// Apply the joins

// For the first join, we need to match all images that are after the given image.
// To do this we need to match 2 conditions
// 1. The resulting images must be within the specified time-window of target image
// 2. The target image's timestamp must be lesser than the timestamp of resulting images
// Combine two filters to match both these conditions
var filter1 = ee.Filter.and(maxDiffFilter, lessEqFilter)
// This join will find all images after, sorted in descending order
// This will gives us images so that closest is last
var join1 = ee.Join.saveAll({
  matchesKey: 'after',
  ordering: 'system:time_start',
  ascending: false})
  
var join1Result = join1.apply({
  primary: filtered,
  secondary: filtered,
  condition: filter1
})
// Each image now as a property called 'after' containing
// all images that come after it within the time-window
print(join1Result.first())

// Do the second join now to match all images within the time-window
// that come before each image
var filter2 = ee.Filter.and(maxDiffFilter, greaterEqFilter)
// This join will find all images before, sorted in ascending order
// This will gives us images so that closest is last
var join2 = ee.Join.saveAll({
  matchesKey: 'before',
  ordering: 'system:time_start',
  ascending: true})
  
var join2Result = join2.apply({
  primary: join1Result,
  secondary: join1Result,
  condition: filter2
})

// Each image now as a property called 'before' containing
// all images that come after it within the time-window
print(join2Result.first())


// Do the interpolation

// We now write a function that will be used to interpolate all images
// This function takes an image and replaces the masked pixels
// with the interpolated value from before and after images.

var interpolateImages = function(image) {
  var image = ee.Image(image)
  // We get the list of before and after images from the image property
  // Mosaic the images so we a before and after image with the closest unmasked pixel
  var beforeImages = ee.List(image.get('before'))
  var beforeMosaic = ee.ImageCollection.fromImages(beforeImages).mosaic()
  var afterImages = ee.List(image.get('after'))
  var afterMosaic = ee.ImageCollection.fromImages(afterImages).mosaic()

  // Interpolation formula
  // y = y1 + (y2-y1)*((t – t1) / (t2 – t1))
  // y = interpolated image
  // y1 = before image
  // y2 = after image
  // t = interpolation timestamp
  // t1 = before image timestamp
  // t2 = after image timestamp
  
  // We first compute the ratio (t – t1) / (t2 – t1)

  // Get image with before and after times
  var t1 = beforeMosaic.select('timestamp').rename('t1')
  var t2 = afterMosaic.select('timestamp').rename('t2')

  var t = image.metadata('system:time_start').rename('t')

  var timeImage = ee.Image.cat([t1, t2, t])

  var timeRatio = timeImage.expression('(t - t1) / (t2 - t1)', {
    't': timeImage.select('t'),
    't1': timeImage.select('t1'),
    't2': timeImage.select('t2'),
  })
  // You can replace timeRatio with a constant value 0.5
  // if you wanted a simple average
  
  // Compute an image with the interpolated image y
  var interpolated = beforeMosaic
    .add((afterMosaic.subtract(beforeMosaic).multiply(timeRatio)))
  // Replace the masked pixels in the current image with the average value
  var result = image.unmask(interpolated)
  return result.copyProperties(image, ['system:time_start'])
}

// map() the function to interpolate all images in the collection
var dataset = ee.ImageCollection(join2Result.map(interpolateImages))

//reduction _mean
var im_mean = dataset.reduce({
reducer: ee.Reducer.intervalMean(10, 90)});

//reduction _meanb
var im_meanb = dataset.reduce({
reducer: ee.Reducer.intervalMean(5, 20)});

//reduction _meanh
var im_meanh = dataset.reduce({
reducer: ee.Reducer.intervalMean(80, 95)});

var image = im_mean.addBands(im_meanb).addBands(im_meanh);

var reprojected = image
        .reproject(CRSclass, null, 10);

var final_image = reprojected.clip(AOI);


var evi3h = final_image.expression ('(2.5*nir-red*(nir+6*red-7.5*bleue)+1)', {
      'nir': final_image.select('B8_mean_2'),
      'red': final_image.select('B4_mean'),
      'bleue': final_image.select('B2_mean'),
}).rename('evi3h');
Map.addLayer(evi3h,{min:1,max:2, palette: ['red', 'yellow', 'green']},'evi3h_07_09');

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////   Classif    //////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////// TRAIN /////////////////////////

////// OVERLAY

/////////// Creation de la stack de variables train

//Image Stack
var newBands_c = ee.Image([vvmean_q1, vvmean_q8, vvmean_q25, vvmean_q50, evi3h
  ]);

var stack_c = vvmin.addBands(newBands_c);
////Map.addLayer(stack_c,{},'stack_c');

var classified = stack_c.classify(RFclassifier).clip(AOI);
Map.addLayer(classified,{min:0, max:5, palette: [
  'white',
  'darkblue',
  'blue',
  'dodgerblue',
  'aqua',
  'yellow'
  ]},'classif_submersion');
  
var sieved = classified.focalMode(3);
Map.addLayer(sieved,{min:0, max:5, palette: [
  'white',
  'darkblue',
  'blue',
  'dodgerblue',
  'aqua',
  'yellow'
  ]},'sieved');
  
/////// Accuracy Assessment

// Get a confusion matrix and overall accuracy for the training sample.
var trainAccuracy = RFclassifier.confusionMatrix();

print('Training error matrix', trainAccuracy);
print('Training overall accuracy', trainAccuracy.accuracy());


// Get a confusion matrix and overall accuracy for the validation sample.
validation = validation.classify(RFclassifier);

var validationAccuracy = validation.errorMatrix('Class', 'classification');

print('Validation error matrix', validationAccuracy);
print('Validation accuracy', validationAccuracy.accuracy());


/////// Variable Importance
var explain = RFclassifier.explain();
print(explain, 'Explain');


//Variable Importance of RF Classifier
var variable_importance = ee.Feature(null, ee.Dictionary(explain).get('importance'));

// Chart of Variable Importance of RF Classifier
var chartTitle = 'Random Forest: Bands Variable Importance';

var chart = ui.Chart.feature.byProperty(variable_importance)
      .setChartType('BarChart')
      .setOptions({
        title: chartTitle,
        legend: {position: 'none'},
        hAxis: {title: 'Importance'},
        vAxis: {title: 'Bands'}
      });

// Chart: Location and Plot
chart.style().set({
  position: 'bottom-left',
  width: '600px',
  height: '600px'
});

Map.add(chart);



////////// EXPORTS CLASSIF

var classified = classified.clip(AOI);
Export.image.toDrive({
  image: classified 
 , folder: dossier,
  description: 'classified',
  scale: 10,
  maxPixels: 1303663927,
  crs:CRSclass,
  crsTransform:'',
  region: AOI
});

var sieved = sieved.clip(AOI);
Export.image.toDrive({
  image: sieved 
 , folder: dossier,
  description: 'sieved',
  scale: 10,
  maxPixels: 1303663927,
  crs:CRSclass,
  crsTransform:'',
  region: AOI
});


var evi3h = evi3h.clip(AOI);
Export.image.toDrive({
  image: evi3h 
 , folder: dossier,
  description: 'evi3h',
  scale: 10,
  maxPixels: 1303663927,
  crs:CRSclass,
  crsTransform:'',
  region: AOI
});

var vvmean_q90 = vvmean_q90.clip(AOI);
Export.image.toDrive({
  image: vvmean_q90 
 , folder: dossier,
  description: 'vvmean_q90',
  scale: 10,
  maxPixels: 1303663927,
  crs:CRSclass,
  crsTransform:'',
  region: AOI
});

var vvmean_q75 = vvmean_q75.clip(AOI);
Export.image.toDrive({
  image: vvmean_q75 
 , folder: dossier,
  description: 'vvmean_q75',
  scale: 10,
  maxPixels: 1303663927,
  crs:CRSclass,
  crsTransform:'',
  region: AOI
});

var vvmean_q50 = vvmean_q50.clip(AOI);
Export.image.toDrive({
  image: vvmean_q50 
 , folder: dossier,
  description: 'vvmean_q50',
  scale: 10,
  maxPixels: 1303663927,
  crs:CRSclass,
  crsTransform:'',
  region: AOI
});

var vvmean_q25 = vvmean_q25.clip(AOI);
Export.image.toDrive({
  image: vvmean_q25 
 , folder: dossier,
  description: 'vvmean_q25',
  scale: 10,
  maxPixels: 1303663927,
  crs:CRSclass,
  crsTransform:'',
  region: AOI
});

var vvmean_q8 = vvmean_q8.clip(AOI);
Export.image.toDrive({
  image: vvmean_q8 
 , folder: dossier,
  description: 'vvmean_q8',
  scale: 10,
  maxPixels: 1303663927,
  crs:CRSclass,
  crsTransform:'',
  region: AOI
});

var vvmean_q1 = vvmean_q1.clip(AOI);
Export.image.toDrive({
  image: vvmean_q1 
 , folder: dossier,
  description: 'vvmean_q1',
  scale: 10,
  maxPixels: 1303663927,
  crs:CRSclass,
  crsTransform:'',
  region: AOI
});

